{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center>Linear Classifier with Pytorch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents</h1>\n",
    "\n",
    "<div font = 3>\n",
    "\n",
    "1. <a href = #obj>Objective</a>\n",
    "2. <a href = #lib>Import Libraries and Auxiliary Function</a>\n",
    "3. <a href = #data>Download Data</a>\n",
    "4. <a href = #class>Dataset Class</a>\n",
    "5. <a href = #trans>Transform Object and Dataset Object</a>\n",
    "6. <a href = #q>Question</a>\n",
    "\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = obj>Objectives</h2>\n",
    "\n",
    "<ul><li> How to use linear classifier in pytorch.</li></ul> \n",
    "\n",
    "Before you use a  Deep neural network to solve the classification problem,  it 's a good idea to try and solve the problem with the simplest method. You will need the dataset object from the previous section.\n",
    "In this lab, we solve the problem with a linear classifier.\n",
    "\n",
    "\n",
    "You will be asked to determine the maximum accuracy your linear classifier can achieve on the validation data for 5 epochs. We will give some free parameter values if you follow the instructions you will be able to answer the quiz. Just like the other labs there are several steps, but in this lab you will only be quizzed on the final result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = lib>Import Libraries and Auxiliary Functions</h2>\n",
    "\n",
    "The following are the libraries we are going to use for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "from typing import Tuple,List,Dict,Union, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = data>Download Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For downloading the dataset of images\n",
    "try:\n",
    "    # Check if the directory exists and create the direction\n",
    "    os.mkdir(os.getcwd()+'/..'+'/images')\n",
    "    # If the path of the images doesn't exists it downloads the images\n",
    "    if not os.path.exists(os.path.join(os.getcwd(),'..','images','Negative')):\n",
    "        with zipfile.ZipFile('concrete_crack_images_for_classification.zip', 'r') as f:\n",
    "            f.extractall(os.path.abspath(os.getcwd())+'\\..'+'\\images')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = class>Dataset Class</h2>\n",
    "\n",
    "In this section, we will use the previous code to build a dataset class. As before, make sure the even samples are positive, and the odd samples are negative.  In this case, if the parameter <code>train</code> is set to <code>True</code>, use the first 10 000 samples as training data; otherwise, the last 10 000 samples will be used as validation data. Do not forget to sort your files so they are in the same order.  \n",
    "\n",
    "**Note:** We are using the first 10,000 samples as our training data instead of the available 30,000 to decrease the training time of the model. If you want, you can train it yourself with all 30,000 samples just by modifying 2 lines in the following code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self,transform = None,train:bool = True, portion:bool = True):\n",
    "        directory = os.path.join(os.getcwd(),'..','images')\n",
    "        positive = 'Positive'\n",
    "        negative = 'Negative'\n",
    "\n",
    "        # Paths and files\n",
    "        positive_path = os.path.join(directory, positive)\n",
    "        negative_path = os.path.join(directory, negative)\n",
    "        positive_files = [os.path.join(positive_path,file) for file in  os.listdir(positive_path) if file.endswith(\".jpg\")]\n",
    "        positive_files.sort()\n",
    "        negative_files=[os.path.join(negative_path,file) for file in  os.listdir(negative_path) if file.endswith(\".jpg\")]\n",
    "        negative_files.sort()\n",
    "\n",
    "        self.number_of_samples = len(positive_files) + len(negative_files)\n",
    "\n",
    "        # Atrributes\n",
    "        self.all_files = [None]*self.number_of_samples\n",
    "        self.all_files[::2] = positive_files\n",
    "        self.all_files[1::2] = negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y = torch.zeros([self.number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2] = 1\n",
    "        self.Y[1::2] = 0\n",
    "        # To use all the training data or not\n",
    "        if portion:\n",
    "            part = 10_000\n",
    "        else:\n",
    "            part = 30_000\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:part] #Change to 30000 to use the full test dataset\n",
    "            self.Y=self.Y[0:part] #Change to 30000 to use the full test dataset\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)    \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx:int):\n",
    "        image=Image.open(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = trans>Transform Object and Dataset Object</h2>\n",
    "\n",
    "Create a transform object, that uses the <code>Compose</code> function. First use the transform <code>ToTensor()</code> and followed by <code>Normalize(mean, std)</code>. The value for <code> mean</code> and <code>std</code> are provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform =transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create object for the training data  <code>dataset_train</code> and validation <code>dataset_val</code>. Use the transform object to convert the images to tensors using the transform object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Data(transform=transform,train=True)\n",
    "dataset_val = Data(transform=transform,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the shape of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 227, 227])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = q> Question </h2>\n",
    "\n",
    "Create a custom module for Softmax for two classes,called model. The input size should be the <code>size_of_image</code>, you should record the maximum accuracy achieved on the validation data for the different epochs. For example if the 5 epochs the accuracy was 0.5, 0.2, 0.64,0.77, 0.66 you would select 0.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the following free parameter values:\n",
    "\n",
    "<b>Parameter Values</b>\n",
    "   <li>learning rate: 0.1 </li>\n",
    "   <li>momentum term: 0.1 </li>\n",
    "   <li>batch size training: 5</li>\n",
    "   <li>Loss function: Cross Entropy Loss </li>\n",
    "   <li>epochs: 5</li>\n",
    "   <li>set: torch.manual_seed(0)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Manual_seed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f3c71d4fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Custom Module:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self,input_size:int = 227*227*3,output_size:int = 2):\n",
    "        super(Softmax,self).__init__()\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "    def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Softmax(\n",
       "  (linear): Linear(in_features=154587, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Softmax()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr = 0.1, momentum=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader Training and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train,batch_size=5)\n",
    "val_loader = DataLoader(dataset_val,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:Softmax, criterion:nn.CrossEntropyLoss,train_loader:DataLoader,\n",
    "          validation_loader:DataLoader, optimizer:optim.SGD,\n",
    "          epochs:int = 100, verbose:int = 0) -> Dict:\n",
    "    train_loss, val_acc = [],[]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total = 0\n",
    "        for x,y  in train_loader:\n",
    "            z = model(x.view(-1,227*227*3))\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(z,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += loss.item()\n",
    "        \n",
    "        train_loss.append(total)\n",
    "\n",
    "        correct = 0\n",
    "        for x,y in validation_loader:\n",
    "            yhat = model(x.view(-1,227*227*3))\n",
    "            _,label = torch.max(yhat,1)\n",
    "            correct += (label==y).sum().item()\n",
    "        accuracy = 100 * (correct / len(dataset_val))\n",
    "\n",
    "        val_acc.append(accuracy)\n",
    "        \n",
    "        if verbose != 0:\n",
    "            if ((epoch + 1) % verbose == 0):\n",
    "                print(f'Epoch [{(epoch + 1):>4d}]: Cost = {total:>8.4f} | Accuracy = {accuracy:>8.4f}')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    hist = {'training_loss':train_loss,'validation_accuracy':val_acc}\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [   1]: Cost = 1964074.4299 | Accuracy =  81.4200\n",
      "Epoch [   2]: Cost = 1397367.7476 | Accuracy =  70.6700\n",
      "Epoch [   3]: Cost = 1265354.7851 | Accuracy =  83.4000\n",
      "Epoch [   4]: Cost = 1157045.0106 | Accuracy =  69.0800\n",
      "Epoch [   5]: Cost = 1090768.4316 | Accuracy =  82.6100\n"
     ]
    }
   ],
   "source": [
    "hist = train(model,criterion,train_loader,val_loader,optimizer,5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model in path of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'.\\saved_models\\linearclassifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
